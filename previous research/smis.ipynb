{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "smis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8--I0E2txTce",
        "outputId": "f61f3583-674d-4292-f383-a822de29e218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd drive/My\\ Drive/SMIS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/SMIS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US63dunWxdSf",
        "outputId": "69e6bdc7-7a8d-49db-acd7-41f5ccc62ebd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "!pip install dominate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading https://files.pythonhosted.org/packages/c0/03/1ba70425be63f2aab42fbc98894fe5d90cdadd41f79bdc778b3e404cfd8f/dominate-2.5.2-py2.py3-none-any.whl\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kpa0EqzxMib",
        "outputId": "7f9e546c-bf8e-4639-b759-20faeaa4e7c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!python test.py --name deepfashion_smis --dataset_mode deepfashion --dataroot \"home/zlxu/data/deepfashion\" --no_instance \\\n",
        "--gpu_ids 1 --ngf 160 --batchSize 4 --model smis --netG deepfashion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux_dvqq_SZiY",
        "outputId": "1bb3c332-8085-4fef-c725-3dc74996f507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python train.py --name deepfashion_smis --dataset_mode deepfashion --dataroot \"home/zlxu/data/deepfashion\" --no_instance \\\n",
        "--gpu_ids 1 --ngf 160 --batchSize 2 --model smis --netG deepfashion"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.py --name deepfashion_smis --dataset_mode deepfashion --dataroot home/zlxu/data/deepfashion --no_instance --gpu_ids 1 --ngf 160 --batchSize 2 --model smis --netG deepfashion\n",
            "30000\n",
            "dataset [DeepfashionDataset] of size 30000 was created\n",
            "Network [DeepFashionGenerator] was created. Total number of parameters: 96.3 million. To see the architecture, do print(network).\n",
            "Network [MultiscaleDiscriminator] was created. Total number of parameters: 5.5 million. To see the architecture, do print(network).\n",
            "Network [ConvEncoder] was created. Total number of parameters: 12.8 million. To see the architecture, do print(network).\n",
            "\n",
            "SmisModel(\n",
            "  (netG): DeepFashionGenerator(\n",
            "    (fc): Conv2d(64, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "    (head_0): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      (conv_1): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      )\n",
            "    )\n",
            "    (G_middle_0): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      (conv_1): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "      )\n",
            "    )\n",
            "    (G_middle_1): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      (conv_1): Conv2d(2560, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      )\n",
            "    )\n",
            "    (up_0): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      (conv_1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      (conv_s): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1), groups=4, bias=False)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "        (mlp_beta): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      )\n",
            "      (norm_s): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(2560, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "        (mlp_beta): Conv2d(128, 2560, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4)\n",
            "      )\n",
            "    )\n",
            "    (up_1): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      (conv_1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      (conv_s): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "        (mlp_beta): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(640, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "        (mlp_beta): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      )\n",
            "      (norm_s): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "        (mlp_beta): Conv2d(128, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      )\n",
            "    )\n",
            "    (up_2): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      (conv_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      (conv_s): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), groups=2, bias=False)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(640, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "        (mlp_beta): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "        (mlp_beta): Conv2d(128, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      )\n",
            "      (norm_s): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(640, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "        (mlp_beta): Conv2d(128, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2)\n",
            "      )\n",
            "    )\n",
            "    (up_3): SPADEV2ResnetBlock(\n",
            "      (conv_0): Conv2d(320, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (conv_s): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm_0): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (mlp_beta): Conv2d(128, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (norm_1): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(160, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (mlp_beta): Conv2d(128, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "      (norm_s): GROUP_SPADE(\n",
            "        (param_free_norm): SynchronizedBatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
            "        (mlp_shared): Sequential(\n",
            "          (0): Conv2d(8, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "          (1): ReLU()\n",
            "        )\n",
            "        (mlp_gamma): Conv2d(128, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (mlp_beta): Conv2d(128, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (conv_img): Conv2d(160, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (up): Upsample(scale_factor=2.0, mode=nearest)\n",
            "  )\n",
            "  (netD): MultiscaleDiscriminator(\n",
            "    (discriminator_0): NLayerDiscriminator(\n",
            "      (model0): Sequential(\n",
            "        (0): Conv2d(11, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model1): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model2): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model3): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model4): Sequential(\n",
            "        (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "      )\n",
            "    )\n",
            "    (discriminator_1): NLayerDiscriminator(\n",
            "      (model0): Sequential(\n",
            "        (0): Conv2d(11, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model1): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model2): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model3): Sequential(\n",
            "        (0): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "        )\n",
            "        (1): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "      (model4): Sequential(\n",
            "        (0): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (netE): ConvEncoder(\n",
            "    (layer1): Sequential(\n",
            "      (0): Conv2d(24, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (1): InstanceNorm2d(1024, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (1): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (layer5): Sequential(\n",
            "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (1): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (layer6): Sequential(\n",
            "      (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=8, bias=False)\n",
            "      (1): InstanceNorm2d(2048, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    )\n",
            "    (fc_mu): Conv2d(2048, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "    (fc_var): Conv2d(2048, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8)\n",
            "    (actvn): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (criterionGAN): GANLoss()\n",
            "  (criterionFeat): L1Loss()\n",
            "  (criterionVGG): VGGLoss(\n",
            "    (vgg): VGG19(\n",
            "      (slice1): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "      )\n",
            "      (slice2): Sequential(\n",
            "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (6): ReLU(inplace=True)\n",
            "      )\n",
            "      (slice3): Sequential(\n",
            "        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (8): ReLU(inplace=True)\n",
            "        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (11): ReLU(inplace=True)\n",
            "      )\n",
            "      (slice4): Sequential(\n",
            "        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (13): ReLU(inplace=True)\n",
            "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (15): ReLU(inplace=True)\n",
            "        (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (17): ReLU(inplace=True)\n",
            "        (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (20): ReLU(inplace=True)\n",
            "      )\n",
            "      (slice5): Sequential(\n",
            "        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (22): ReLU(inplace=True)\n",
            "        (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (24): ReLU(inplace=True)\n",
            "        (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (26): ReLU(inplace=True)\n",
            "        (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (29): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (criterion): L1Loss()\n",
            "  )\n",
            "  (KLDLoss): KLDLoss()\n",
            ")\n",
            "create web directory ./checkpoints/deepfashion_smis/web...\n",
            "------------------------------------------------\n",
            "/content/drive/My Drive/SMIS/models/smis_model.py:235: UserWarning: This overload of nonzero is deprecated:\n",
            "\tnonzero()\n",
            "Consider using one of the following signatures instead:\n",
            "\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
            "  y_id = y_seg.nonzero()\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "tensor(0.0019, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.1532, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3350, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3593, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0022, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.1769, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3880, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4046, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "------------------------------------------------\n",
            "tensor(0.0081, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.2717, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3980, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4092, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0063, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.2650, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3848, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4005, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "------------------------------------------------\n",
            "tensor(0.0098, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3249, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3966, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3840, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0090, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3167, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3805, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3944, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "------------------------------------------------\n",
            "tensor(0.0140, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3587, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4565, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4781, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0119, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4882, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.5615, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.5675, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "------------------------------------------------\n",
            "tensor(0.0163, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3808, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4592, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4807, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0121, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3612, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4410, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4412, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "------------------------------------------------\n",
            "tensor(0.0136, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3471, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.3454, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.2972, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.0134, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4397, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.4896, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "tensor(0.5078, device='cuda:0', grad_fn=<L1LossBackward>)\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 34, in <module>\n",
            "    for i, data_i in enumerate(dataloader, start=iter_counter.epoch_iter):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 403, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/drive/My Drive/SMIS/data/pix2pix_dataset.py\", line 54, in __getitem__\n",
            "    label = Image.open(label_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/PIL/Image.py\", line 2818, in open\n",
            "    prefix = fp.read(16)\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}